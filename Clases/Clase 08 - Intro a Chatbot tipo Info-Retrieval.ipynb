{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "UQoVRp4gjxUo",
        "nI2FsyUOj3je"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hghx5BwKdm-A"
      },
      "outputs": [],
      "source": [
        "!pip install spacy --quiet\n",
        "!python -m spacy download es_core_news_sm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "import es_core_news_sm\n",
        "nlp = es_core_news_sm.load()\n",
        "\n",
        "doc = nlp(\"Esto es una frase.\")\n",
        "print([(w.text, w.pos_) for w in doc])"
      ],
      "metadata": {
        "id": "D9SRh-eDdpWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbots basados en recuperación\n",
        "\n",
        "En inglés: Information Retrieval Chatbots"
      ],
      "metadata": {
        "id": "UnrG-1ylkncZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motor de búsqueda"
      ],
      "metadata": {
        "id": "s3bs1FmWkfrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Búsqueda por palabras clave: Extrae palabras clave de la pregunta del usuario y busca coincidencias en las preguntas almacenadas.\n",
        "\n",
        "* Similitud del coseno: Si has representado las preguntas como vectores (por ejemplo, usando TF-IDF o word embeddings), puedes usar la similitud del coseno para medir la distancia entre las preguntas.\n",
        "\n",
        "* Word embeddings: Utiliza modelos de word embeddings como Word2Vec o BERT para obtener representaciones semánticas de las preguntas y las consultas del usuario."
      ],
      "metadata": {
        "id": "enbz9kXGkWlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Búsqueda por **Palabras Clave**"
      ],
      "metadata": {
        "id": "UQoVRp4gjxUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tu_diccionario = {\n",
        "  \"hola\": \"¡Hola! ¿En qué puedo ayudarte?\",\n",
        "  \"adiós\": \"Hasta luego. ¡Que tengas un buen día!\",\n",
        "  \"información\": \"¿Qué tipo de información estás buscando?\",\n",
        "  # agrega más entradas de diccionario según tus necesidades\n",
        "}"
      ],
      "metadata": {
        "id": "3BljEMEOhpTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def responder_pregunta(pregunta):\n",
        "  respuesta = \"Lo siento, no entiendo tu pregunta.\"\n",
        "\n",
        "  # procesa la pregunta y convierte a minúsculas\n",
        "  pregunta_procesada = nlp(pregunta.lower())\n",
        "  # print(f\"pregunta_procesada: { pregunta_procesada }\")\n",
        "\n",
        "  # busca una coincidencia en el diccionario\n",
        "  for palabra in pregunta_procesada:\n",
        "\n",
        "    # regresa la primer coincidencia que encuentra\n",
        "    if palabra.text in tu_diccionario:\n",
        "      respuesta = tu_diccionario[palabra.text]\n",
        "      break\n",
        "\n",
        "  return respuesta"
      ],
      "metadata": {
        "id": "Z4q_k1_3hvyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  entrada_usuario = input(\"Tú:       \")\n",
        "\n",
        "  if entrada_usuario.lower() == \"salir\":\n",
        "    print(\"Chatbot: Hasta luego.\")\n",
        "    break\n",
        "\n",
        "  respuesta = responder_pregunta(entrada_usuario)\n",
        "  print(\"Chatbot: \", respuesta)"
      ],
      "metadata": {
        "id": "9gMPKi-ghwcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Búsqueda por **Similitud**"
      ],
      "metadata": {
        "id": "nI2FsyUOj3je"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para los chatbots basados ​​en recuperación, es común utilizar bolsas de palabras (Bag of Words) o TF-IDF para calcular la similitud de intenciones."
      ],
      "metadata": {
        "id": "AoZIaX0Kj7xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# datos de ejemplo\n",
        "preguntas =   [\"¿Qué es el aprendizaje automático?\",\n",
        "               \"¿Cómo funciona la regresión lineal?\",\n",
        "               \"¿Qué es una bazofia?\"]\n",
        "\n",
        "respuestas =  [\"El aprendizaje automático es una rama de la inteligencia artificial...\",\n",
        "               \"La regresión lineal es un método de modelado...\",\n",
        "               \"La bazofia es bazofia\"]\n",
        "\n",
        "# vectorización con TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(preguntas)"
      ],
      "metadata": {
        "id": "CReIz0ISj75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# función para encontrar la mejor coincidencia\n",
        "def responder_pregunta(consulta_usuario):\n",
        "\n",
        "  consulta_vec = vectorizer.transform([consulta_usuario])\n",
        "\n",
        "  similitudes = cosine_similarity(consulta_vec, tfidf_matrix).flatten()\n",
        "  print(f\"Similitudes: { similitudes }\")\n",
        "\n",
        "  idx_best_match = similitudes.argmax()\n",
        "  print(f\"Respuesta:   #{ idx_best_match }\")\n",
        "\n",
        "  return respuestas[idx_best_match]"
      ],
      "metadata": {
        "id": "0RrQE84HF-d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consulta = \"¿Qué es la regresión lineal?\"\n",
        "# consulta = \"bazofia\"\n",
        "consulta = \"es\"\n",
        "\n",
        "respuesta = responder_pregunta(consulta)\n",
        "print(\"Respuesta:  \", respuesta)"
      ],
      "metadata": {
        "id": "foqaZ1FN583i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Búsqueda por **similitud en Embeddings**"
      ],
      "metadata": {
        "id": "20KCxfCymOHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el paso anterior el texto fue vectorizado usando TF-IDF.\n",
        "\n",
        "Puedes vectorizar el texto usando word embeddings, como vimos en una clase anterior. Puedes mirar el notebook sobre Embeddings.\n"
      ],
      "metadata": {
        "id": "7g6jgLSLnilX"
      }
    }
  ]
}