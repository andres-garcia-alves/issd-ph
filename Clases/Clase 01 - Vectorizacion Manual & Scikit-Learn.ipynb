{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anadiedrichs/procesamientoDelHabla/blob/main/clase_1_vectorizacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5hxxkdAQJg"
      },
      "source": [
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Vectorización\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "kCED1hh-Ioyf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(linewidth=230) # mayor ancho en el print() antes que se genere un salto de línea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA8VS2dVU3tO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOa4JPSCJ29"
      },
      "source": [
        "## Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RIO7b8GjAC17"
      },
      "outputs": [],
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqdaTmO8P1r"
      },
      "source": [
        "Documento 1 --> que dia es hoy \\\n",
        "Documento 2 --> martes el dia de hoy es martes \\\n",
        "Documento 3 --> martes muchas gracias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ccchOeZuShL",
        "outputId": "5688d6ef-38ed-4129-d72a-67e87cc448e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'], dtype='<U30')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHxBRNzCMOS"
      },
      "source": [
        "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
        "- Cada documento transformarlo en una lista de términos\n",
        "- Armar un vector de términos no repetidos de todos los documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZqTOZzDI7uv",
        "outputId": "6e4c9fa4-b1c4-4c71-ff00-620b794044c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['que', 'dia', 'es', 'hoy']), list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']), list(['martes', 'muchas', 'gracias'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "documentos = np.char.split(corpus)\n",
        "documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0GD_Xle81hR",
        "outputId": "6df32140-10d2-498f-839c-bbf5d0ffbaf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# demostración: 'que' está incluido en ['que', 'dia', 'es', 'hoy'] ?\n",
        "np.isin(documentos[0][0], documentos[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAKCtS1Z8YL-",
        "outputId": "791041cc-b7af-4aae-e8f2-8ef07677dc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['que' 'dia' 'es' 'hoy' 'martes' 'el' 'de' 'muchas' 'gracias']\n"
          ]
        }
      ],
      "source": [
        "# construir un array con el vocabulario del corpus\n",
        "tokens = []\n",
        "\n",
        "for doc in documentos:\n",
        "  for word in doc:\n",
        "    if np.isin(word, tokens) == False:\n",
        "      tokens = np.append(tokens,word)\n",
        "      # print(word)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhH983FI7It"
      },
      "source": [
        "### 2- OneHot encoding\n",
        "Dada una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os0AAQo6I6Z1",
        "outputId": "97f08f13-05a6-41f9-a48b-744fcaaef88b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "n_doc = documentos.size     # 3\n",
        "n_tokens = len(tokens)      # 9\n",
        "\n",
        "matriz = np.zeros((n_doc, n_tokens), dtype = np.uint8) # matriz 3x9\n",
        "matriz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCBTuA8XFIMr",
        "outputId": "f9ef176c-7654-4c88-a904-6db6148adf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens\n",
            " ['que' 'dia' 'es' 'hoy' 'martes' 'el' 'de' 'muchas' 'gracias'] \n",
            "\n",
            "documentos\n",
            " [list(['que', 'dia', 'es', 'hoy']) list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']) list(['martes', 'muchas', 'gracias'])] \n",
            "\n",
            "matriz\n",
            " [[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ],
      "source": [
        "fila = 0\n",
        "\n",
        "for doc in documentos:\n",
        "  #print(doc)\n",
        "\n",
        "  for word in doc:\n",
        "    #print(word)\n",
        "    if word in tokens:\n",
        "      tk_idx = tokens.tolist().index(word)\n",
        "      #print(tk_idx)\n",
        "      matriz[fila, tk_idx] = 1\n",
        "\n",
        "  fila = fila + 1\n",
        "\n",
        "print('tokens\\n', tokens, '\\n')\n",
        "print('documentos\\n', documentos, '\\n')\n",
        "print('matriz\\n', matriz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKc6sve-L65_",
        "outputId": "506adbdf-1dad-4fc9-e0b8-685ea3005a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Algoritmo 'One-Hot-Encoding' (implementación final)\n",
        "def one_hot_encoding(documento_list, tokens_list):\n",
        "\n",
        "  n_doc = documento_list.size\n",
        "  n_tokens = len(tokens_list)\n",
        "  matriz = np.zeros((n_doc, n_tokens), dtype = np.uint8) # matriz 3x9\n",
        "  fila = 0\n",
        "\n",
        "  for doc in documento_list:\n",
        "\n",
        "    for word in doc:\n",
        "      if word in tokens_list:\n",
        "        tk_idx = tokens.tolist().index(word)\n",
        "        matriz[fila, tk_idx] = 1\n",
        "\n",
        "    fila = fila + 1\n",
        "\n",
        "  return matriz\n",
        "\n",
        "print(one_hot_encoding(documentos, tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyWGmCpJVQL"
      },
      "source": [
        "### 3- Vectores de frecuencia\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqij_7eHJbUi",
        "outputId": "79e362de-8a5a-4c5e-cb29-8d398c93ea03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "n_doc = documentos.size\n",
        "n_tokens = len(tokens)\n",
        "\n",
        "frecuencias = np.zeros((n_doc, n_tokens), dtype = np.uint8) # matriz 3x9\n",
        "frecuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QoJun74Kdlw",
        "outputId": "e2769bd7-336e-4129-f231-2e051412cc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens\n",
            " ['que' 'dia' 'es' 'hoy' 'martes' 'el' 'de' 'muchas' 'gracias'] \n",
            "\n",
            "documentos\n",
            " [list(['que', 'dia', 'es', 'hoy']) list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']) list(['martes', 'muchas', 'gracias'])] \n",
            "\n",
            "frecuencias\n",
            " [[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ],
      "source": [
        "fila = 0\n",
        "\n",
        "for doc in documentos:\n",
        "  for word in doc:\n",
        "    if word in tokens:\n",
        "      tk_idx = tokens.tolist().index(word)\n",
        "      frecuencias[fila, tk_idx] = frecuencias[fila, tk_idx] + 1   # sumar 1 al valor previo\n",
        "\n",
        "  fila = fila + 1\n",
        "\n",
        "print('tokens\\n', tokens, '\\n')\n",
        "print('documentos\\n', documentos, '\\n')\n",
        "print('frecuencias\\n', frecuencias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd457y3nMop5",
        "outputId": "5fbfe882-3e8e-4618-94c2-1de731f8ebb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ],
      "source": [
        "# Algoritmo 'Frecuency-Matrix' (implementación final)\n",
        "def frecuency_matrix(documento_list, tokens_list):\n",
        "  n_doc = documento_list.size   # 3\n",
        "  n_tokens = len(tokens_list)   # 9\n",
        "\n",
        "  frecuencias = np.zeros((n_doc, n_tokens), dtype = np.uint8)  # matriz 3x9\n",
        "\n",
        "  fila = 0\n",
        "  for doc in documento_list:\n",
        "    for word in doc:\n",
        "      if word in tokens_list:\n",
        "        tk_idx = tokens_list.tolist().index(word)\n",
        "        frecuencias[fila, tk_idx] = frecuencias[fila, tk_idx] + 1\n",
        "\n",
        "    fila = fila + 1\n",
        "\n",
        "  return frecuencias\n",
        "\n",
        "print(frecuency_matrix(documentos, tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ot8HvWJcBu"
      },
      "source": [
        "### 4- TF-IDF\n",
        "Dada una lista de textos, devolver una matriz con la representacion TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "n7S8KxBsUUXR"
      },
      "outputs": [],
      "source": [
        "# Algortimo 'IDF'\n",
        "# se obtiene como la división de la cantidad de documentos, sobre la suma en axis=0 (vertical) del One-Hot-Encoding.\n",
        "def inverse_document_frequency(documento_list, tokens_list):\n",
        "\n",
        "  n_doc = documento_list.size # 3\n",
        "  freq = frecuency_matrix(documento_list, tokens_list)\n",
        "\n",
        "  div = (n_doc * 1.0) / (np.sum(freq, axis=0) * 1.0)\n",
        "  idf = np.log10(div)\n",
        "  #print(' div:', div, '\\n')\n",
        "\n",
        "  return idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waG_oWtpJjRw",
        "outputId": "c2588b70-c33d-449a-a65c-c99c456e8183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF\n",
            " [0.47712125 0.17609126 0.17609126 0.17609126 0.         0.47712125 0.47712125 0.47712125 0.47712125] \n",
            "\n",
            "TF\n",
            " [[1 1 1 1 0 0 0 0 0]\n",
            " [0 1 1 1 2 1 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47712125, 0.17609126, 0.17609126, 0.17609126, 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.17609126, 0.17609126, 0.17609126, 0.        , 0.47712125, 0.47712125, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.47712125, 0.47712125]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# calcular IDF\n",
        "\n",
        "IDF = inverse_document_frequency(documentos, tokens)\n",
        "print('IDF\\n', IDF, '\\n')\n",
        "\n",
        "# calcular TF\n",
        "TF = frecuency_matrix(documentos, tokens)\n",
        "print('TF\\n', TF)\n",
        "\n",
        "# calcular TF-IDF\n",
        "def TF_IDF(documento_list, tokens_list):\n",
        "  return frecuency_matrix(documentos, tokens) * inverse_document_frequency(documentos, tokens)\n",
        "\n",
        "# llamar al algoritmo TF-IDF\n",
        "TF_IDF(documentos, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbEO4NucI_4L"
      },
      "source": [
        "## Usando sklearn para procesar texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOuIzmLMOq6"
      },
      "source": [
        "### Vector de Frecuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "YUNP-x2UL3hV"
      },
      "outputs": [],
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gKQx1Pj7JADt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40241198-6fc4-4d99-bd03-3b5fee06fd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario:\n",
            " ['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que'] \n",
            "\n",
            "Vector de frecuencias\n",
            " [[0 1 0 1 0 1 0 0 1]\n",
            " [1 1 1 1 0 1 2 0 0]\n",
            " [0 0 0 0 1 0 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# fit & transform\n",
        "vectorizer.fit(corpus)\n",
        "vector = vectorizer.transform(corpus)\n",
        "\n",
        "# mostrar el vocabulario y el vector de frecuencias:\n",
        "print('Vocabulario:\\n', vectorizer.get_feature_names_out(), '\\n')\n",
        "print('Vector de frecuencias\\n', vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbD_tE8dMcZN"
      },
      "source": [
        "### One-hot encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHsfwZHdM0Hg"
      },
      "source": [
        "Usar sklearn para obtener la representacion one-hot encoding de un corpus de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5irIx9Z-MzsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6de295-b0ca-46ab-8a78-4b989637cd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario:\n",
            " ['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que'] \n",
            "\n",
            "One-Hot-Encoding:\n",
            " [[0 1 0 1 0 1 0 0 1]\n",
            " [1 1 1 1 0 1 1 0 0]\n",
            " [0 0 0 0 1 0 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Crear un vectorizador para contar la frecuencia de las palabras\n",
        "vectorizer = CountVectorizer(binary=True)  # binary=True para one-hot encoding\n",
        "\n",
        "# Obtener la representación one-hot encoding (fit & transform)\n",
        "vectorizer.fit(corpus)\n",
        "one_hot_vector = vectorizer.transform(corpus)\n",
        "\n",
        "# Mostrar el vocabulario y la matriz resultante\n",
        "print('Vocabulario:\\n', vectorizer.get_feature_names_out(), '\\n')\n",
        "print('One-Hot-Encoding:\\n', one_hot_vector.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzJIEfmMM9nk"
      },
      "source": [
        "## TF-IDF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MYcFAnKvNOjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555712a0-df6a-4f79-ff63-5c095172b851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario:\n",
            " ['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que'] \n",
            "\n",
            "TF-IDF:\n",
            " [[0.         0.45985353 0.         0.45985353 0.         0.45985353 0.         0.         0.60465213]\n",
            " [0.40659827 0.30922846 0.40659827 0.30922846 0.         0.30922846 0.61845693 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.62276601 0.         0.4736296  0.62276601 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Crear un vectorizador TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Ajustar el vectorizador al corpus\n",
        "tfidf_vectorizer.fit(corpus)\n",
        "\n",
        "# Obtener la representación TF-IDF\n",
        "tfidf_matrix = tfidf_vectorizer.transform(corpus)\n",
        "\n",
        "# Mostrar el vocabulario y la matriz TF-IDF\n",
        "print('Vocabulario:\\n', tfidf_vectorizer.get_feature_names_out(), '\\n')\n",
        "print('TF-IDF:\\n', tfidf_matrix.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fps1NU66U4cz"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "**Dado el siguiente texto**\n",
        "\n",
        "Aplastamiento de las Gotas - Julio Cortázar\n",
        "\n",
        "Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\n",
        "\n",
        "Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "grRaq08KVNao"
      },
      "outputs": [],
      "source": [
        "corpus = [\"Aplastamiento de las Gotas - Julio Cortázar\",\n",
        "          \"Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\",\n",
        "          \"Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "i_Z_PpQGZY9X"
      },
      "outputs": [],
      "source": [
        "corpus_dict = [\n",
        "    {\"id\": 0, \"texto\": \"Aplastamiento de las Gotas - Julio Cortázar\"},\n",
        "    {\"id\": 1, \"texto\": \"Yo no sé, mirá, es terrible cómo llueve. Llueve todo el tiempo, afuera tupido y gris, aquí contra el balcón con goterones cuajados y duros, que hacen plaf y se aplastan como bofetadas uno detrás de otro qué hastío. Ahora aparece una gotita en lo alto del marco de la ventana, se queda temblequeando contra el cielo que la triza en mil brillos apagados, va creciendo y se tambalea, ya va a caer y no se cae, todavía no se cae. Está prendida con todas las uñas, no quiere caerse y se la ve que se agarra con los dientes mientras le crece la barriga, ya es una gotaza que cuelga majestuosa y de pronto zup ahí va, plaf, deshecha, nada, una viscosidad en el mármol.\"},\n",
        "    {\"id\": 2, \"texto\": \"Pero las hay que se suicidan y se entregan enseguida, brotan en el marco y ahí mismo se tiran; me parece ver la vibración del salto, sus piernitas desprendiéndose y el grito que las emborracha en esa nada del caer y aniquilarse. Tristes gotas, redondas inocentes gotas. Adiós gotas. Adiós.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE_ocIdPIOMi"
      },
      "source": [
        "### Usar la librería Numpy y sklearn para calcular el Vector de Frecuencias, One-Hot-Encoding, y TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "IkZjOicpIVS9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# aumentar ancho al momento del print(), antes que se genere un salto de línea\n",
        "np.set_printoptions(linewidth=230)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VECTOR DE FRECUENCIAS\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# fit & transform\n",
        "count_vectorizer.fit(corpus)\n",
        "vector = count_vectorizer.transform(corpus)\n",
        "\n",
        "# mostrar el vocabulario y el vector de frecuencias:\n",
        "print('Vector de frecuencias: \\n')\n",
        "print('- Vocabulario\\n {0} \\n'.format(count_vectorizer.get_feature_names_out()))\n",
        "print('- Matriz\\n {0}'.format(vector.toarray()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xHe7WK2fPl_",
        "outputId": "e668102c-2089-4b53-f18d-4cf51de623d0"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector de frecuencias: \n",
            "\n",
            "- Vocabulario\n",
            " ['adiós' 'afuera' 'agarra' 'ahora' 'ahí' 'alto' 'aniquilarse' 'apagados' 'aparece' 'aplastamiento' 'aplastan' 'aquí' 'balcón' 'barriga' 'bofetadas' 'brillos' 'brotan' 'cae' 'caer' 'caerse' 'cielo' 'como' 'con' 'contra' 'cortázar'\n",
            " 'crece' 'creciendo' 'cuajados' 'cuelga' 'cómo' 'de' 'del' 'deshecha' 'desprendiéndose' 'detrás' 'dientes' 'duros' 'el' 'emborracha' 'en' 'enseguida' 'entregan' 'es' 'esa' 'está' 'gotas' 'gotaza' 'goterones' 'gotita' 'gris'\n",
            " 'grito' 'hacen' 'hastío' 'hay' 'inocentes' 'julio' 'la' 'las' 'le' 'llueve' 'lo' 'los' 'majestuosa' 'marco' 'me' 'mientras' 'mil' 'mirá' 'mismo' 'mármol' 'nada' 'no' 'otro' 'parece' 'pero' 'piernitas' 'plaf' 'prendida' 'pronto'\n",
            " 'que' 'queda' 'quiere' 'qué' 'redondas' 'salto' 'se' 'suicidan' 'sus' 'sé' 'tambalea' 'temblequeando' 'terrible' 'tiempo' 'tiran' 'todas' 'todavía' 'todo' 'tristes' 'triza' 'tupido' 'una' 'uno' 'uñas' 'va' 've' 'ventana' 'ver'\n",
            " 'vibración' 'viscosidad' 'ya' 'yo' 'zup'] \n",
            "\n",
            "- Matriz\n",
            " [[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 2 1 1 1 1 3 2 0 1 1 1 1 1 3 1 1 0 1 1 1 4 0 3 0 0 2 0 1 0 1 1 1 1 0 1 1 0 0 0 4 1 1 2 1 1 1 1 0 1 1 1 0 1 1 4 1 0 0 0 2 1 1 4 1 1 1 0 0 7 0 0 1 1 1 1 1 0 1 1 1 0 1 1 3 1 1 3 1 1 0 0 1 2 1 1]\n",
            " [2 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 2 1 2 1 1 0 1 0 3 0 0 0 0 1 0 0 1 1 0 1 2 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 2 0 0 0 1 1 3 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONE-HOT-ENCONDING\n",
        "one_hot_vectorizer = CountVectorizer(binary=True)  # binary=True para one-hot-encoding\n",
        "\n",
        "# fit & transform: obtener la representación one-hot-encoding\n",
        "one_hot_vectorizer.fit(corpus)\n",
        "one_hot_vector = one_hot_vectorizer.transform(corpus)\n",
        "\n",
        "# Mostrar el vocabulario y la matriz resultante\n",
        "print('\\nOne-Hot-Encoding: \\n')\n",
        "print('- Vocabulario\\n {0} \\n'.format(one_hot_vectorizer.get_feature_names_out()))\n",
        "print('- Matriz\\n {0}'.format(one_hot_vector.toarray()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpjmPp4mfQie",
        "outputId": "8008bd6a-1946-4eb0-de17-9173e89955f7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "One-Hot-Encoding: \n",
            "\n",
            "- Vocabulario\n",
            " ['adiós' 'afuera' 'agarra' 'ahora' 'ahí' 'alto' 'aniquilarse' 'apagados' 'aparece' 'aplastamiento' 'aplastan' 'aquí' 'balcón' 'barriga' 'bofetadas' 'brillos' 'brotan' 'cae' 'caer' 'caerse' 'cielo' 'como' 'con' 'contra' 'cortázar'\n",
            " 'crece' 'creciendo' 'cuajados' 'cuelga' 'cómo' 'de' 'del' 'deshecha' 'desprendiéndose' 'detrás' 'dientes' 'duros' 'el' 'emborracha' 'en' 'enseguida' 'entregan' 'es' 'esa' 'está' 'gotas' 'gotaza' 'goterones' 'gotita' 'gris'\n",
            " 'grito' 'hacen' 'hastío' 'hay' 'inocentes' 'julio' 'la' 'las' 'le' 'llueve' 'lo' 'los' 'majestuosa' 'marco' 'me' 'mientras' 'mil' 'mirá' 'mismo' 'mármol' 'nada' 'no' 'otro' 'parece' 'pero' 'piernitas' 'plaf' 'prendida' 'pronto'\n",
            " 'que' 'queda' 'quiere' 'qué' 'redondas' 'salto' 'se' 'suicidan' 'sus' 'sé' 'tambalea' 'temblequeando' 'terrible' 'tiempo' 'tiran' 'todas' 'todavía' 'todo' 'tristes' 'triza' 'tupido' 'una' 'uno' 'uñas' 'va' 've' 'ventana' 'ver'\n",
            " 'vibración' 'viscosidad' 'ya' 'yo' 'zup'] \n",
            "\n",
            "- Matriz\n",
            " [[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
            " [1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tf_idf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Ajustar el vectorizador al corpus\n",
        "tf_idf_vectorizer.fit(corpus)\n",
        "\n",
        "# Obtener la representación TF-IDF\n",
        "tf_idf_matrix = tfidf_vectorizer.transform(corpus)\n",
        "\n",
        "# Mostrar el vocabulario y la matriz TF-IDF\n",
        "print('\\nTF-IDF: \\n')\n",
        "print('- Vocabulario\\n {0} \\n'.format(tf_idf_vectorizer.get_feature_names_out()))\n",
        "print('- Matriz\\n {0}'.format(tf_idf_matrix.toarray()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLmjDbS6fQB3",
        "outputId": "cde89da5-53ca-4d96-bcd8-d02c19466eab"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF: \n",
            "\n",
            "- Vocabulario\n",
            " ['adiós' 'afuera' 'agarra' 'ahora' 'ahí' 'alto' 'aniquilarse' 'apagados' 'aparece' 'aplastamiento' 'aplastan' 'aquí' 'balcón' 'barriga' 'bofetadas' 'brillos' 'brotan' 'cae' 'caer' 'caerse' 'cielo' 'como' 'con' 'contra' 'cortázar'\n",
            " 'crece' 'creciendo' 'cuajados' 'cuelga' 'cómo' 'de' 'del' 'deshecha' 'desprendiéndose' 'detrás' 'dientes' 'duros' 'el' 'emborracha' 'en' 'enseguida' 'entregan' 'es' 'esa' 'está' 'gotas' 'gotaza' 'goterones' 'gotita' 'gris'\n",
            " 'grito' 'hacen' 'hastío' 'hay' 'inocentes' 'julio' 'la' 'las' 'le' 'llueve' 'lo' 'los' 'majestuosa' 'marco' 'me' 'mientras' 'mil' 'mirá' 'mismo' 'mármol' 'nada' 'no' 'otro' 'parece' 'pero' 'piernitas' 'plaf' 'prendida' 'pronto'\n",
            " 'que' 'queda' 'quiere' 'qué' 'redondas' 'salto' 'se' 'suicidan' 'sus' 'sé' 'tambalea' 'temblequeando' 'terrible' 'tiempo' 'tiran' 'todas' 'todavía' 'todo' 'tristes' 'triza' 'tupido' 'una' 'uno' 'uñas' 'va' 've' 'ventana' 'ver'\n",
            " 'vibración' 'viscosidad' 'ya' 'yo' 'zup'] \n",
            "\n",
            "- Matriz\n",
            " [[1.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.45583653 0.         0.60778204 0.23111695 0.         0.         0.         0.         0.60778204]\n",
            " [0.         0.         0.70710678 0.         0.         0.         0.         0.         0.70710678]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DMOa4JPSCJ29",
        "_rOuIzmLMOq6",
        "SbD_tE8dMcZN",
        "uzJIEfmMM9nk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}